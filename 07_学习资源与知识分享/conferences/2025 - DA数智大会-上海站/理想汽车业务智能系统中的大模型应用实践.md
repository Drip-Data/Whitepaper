# 理想汽车业务智能系统中的大模型应用实践

## 概述

本文档梳理了理想汽车在构建企业内部业务智能（BI）系统时，利用大模型原生能力的思考和实践。重点内容围绕**智能取数(NL2SQL)\**和\**数据分析Agent**两大方向展开。

------

## 一、业务智能系统演进路径

### 演进阶段

理想汽车提出了从L2 BI到L5 Species（数据分析硅基同事）的演进路径：

- **目标**：实现碳基员工与AI的深度协作
- 技术路线演进：
  1. 机器学习+规则
  2. 大模型+Prompt+KG
  3. 决策大模型+RL
  4. 认知大模型+自主进化

### 发展规划

- **2024年**：认知BI 1.0（智能取数、报表搭建）
- **2025年**：数据分析Agent

------

## 二、NL2SQL实践（认知BI 1.0）

### 阶段一：知识内化(SFT)

- **实现方式**：通过SFT将行业知识和数据（指标、维度表等）内化到模型
- 技术特点：
  - 结合提示词工程（One-shot显著提升效果）
  - 完成动态知识召回
- **成果**：单表取数准确率达80%
- **不足**：多表取数幻觉严重，泛化性差

### 阶段二：能力内化(2*SFT + DPO)

- **实现方式**：分阶段学习范式
- 技术路线：
  1. 基于Qwen系列模型
  2. 领域二次预训练
  3. SFT1（领域任务适配）
  4. SFT2（领域任务精准萃取）
  5. DPO（借鉴TPO思想，构建拒绝采样三元组）
- **成果**：准确率达90%，有效控制幻觉

------

## 三、长CoT推理与Test-time Compute

### 技术回顾

- 通过Test-time Compute（如MCTS、Beam Search等搜索方法）提升模型推理能力
- 使用搜索算法求解最优路径
- 应用Rule Reward Function评估路径质量

### MCTS在NL2SQL中的实验

- **方法**：将NL2SQL任务划分难度等级，验证MCTS数据合成效果
- **成果**：5轮Rollout可达SOTA 98%准确率

### MCTS应用优化

- **问题**：MCTS直接应用在线推理延迟高

- 解决方案

  ：离线MCTS + 在线推理

  - **离线阶段**：MCTS Rollout探索并归纳"思维模式库"
  - **在线阶段**：模式匹配和执行

- **成果**：基于GPT-4o的实现准确率超越人类专家

------

## 四、长CoT推理与Distillation & RL

### 知识蒸馏回顾

- 通过知识蒸馏(KD)将大模型的知识和技能迁移到小模型
- SFT本质是能力的搬运工

### GRPO算法引入

- 借鉴DeepSeekMath/R1中的GRPO算法
- 相比PPO的简化：
  - 取消了Value Model
  - 取消了Reward Model
- 优势：RL训练更简单高效

### 开发范式再升级(2*SFT + GRPO)

- **演进**：从2*SFT+DPO到2*SFT蒸馏+GRPO能力增强
- 过程：
  1. SFT进行预热和能力初步蒸馏
  2. GRPO增强推理能力
- 发现：
  - 非结构化CoT不适用小模型
  - 半结构化CoT可能是更好的解法
- **成果**：线上准确率达95%

------

## 五、Agent探索（认知BI 2.0）

### 基本观点

- Agent是未来发展趋势
- 当前模型IQ已足够高，可支持Agent实现

### Agent实现方案

- **框架**：基于Workflow的实现方案（One system more workflow）
- 执行步骤：
  1. 意图路由
  2. 算子选择
  3. 策略执行

### Workflow泛化

- **思路**：借鉴FlowReasoner的思想
- **实现**：通过Reasoning-based Meta-Agent针对不同Query动态生成Workflow
- **演进**：从"One-size-fits-all"到"One query one workflow"

------

## 六、对比与启发（针对Datapresso/LIMO）

### 共同点

1. **能力提升路径**：
   - 都探索了从基础SFT到更高级训练范式（RL/DPO/GRPO）的演进
   - 目标均为提升模型在特定任务上的能力和推理水平
2. **数据合成/增强**：
   - 都认识到数据的关键作用
   - 理想汽车：MCTS探索生成数据
   - LIMO：LLM生成数据
3. **注重推理能力**：
   - 都关注模型的推理能力
   - 重视CoT (Chain-of-Thought)的应用

### 不同点

1. **应用焦点**：
   - 理想汽车：企业内部BI场景的NL2SQL和数据分析Agent
   - LIMO：通用的高质量微调数据Pipeline
2. **模型演进路径**：
   - 理想汽车：清晰的迭代路径（知识内化→能力内化→推理增强→Agent）
   - LIMO：目前聚焦于数据构建环节
3. **核心技术**：
   - 理想汽车：深入应用MCTS、TPO/DPO、GRPO、Workflow Agent
   - LIMO：规划中涉及LLM评估器、IFD、LIMR等

### 启发与思考

1. **分阶段训练范式**：
   - 理想汽车的SFT→2*SFT+DPO→2*SFT+GRPO演进路径值得借鉴
   - LIMO可扩展支持多阶段训练数据生成
   - 从基础SFT数据到DPO偏好数据或GRPO的CoT数据
2. **半结构化CoT**：
   - 对小模型（<14B），半结构化CoT可能优于非结构化CoT
   - LIMO生成CoT数据时可引入结构化或半结构化表示
3. **MCTS数据探索与合成**：
   - MCTS可用于探索最优推理路径并合成高质量数据
   - LIMO框架可借鉴"离线探索+在线模式匹配"思路
4. **特定训练格式数据**：
   - LIMO Pipeline需考虑生成特定RL算法所需的数据格式
   - 如DPO的偏好对（chosen/rejected）
   - GRPO的CoT样本
5. **能力内化vs知识内化**：
   - 从简单SFT内化知识到通过多阶段训练和RL内化"能力"
   - LIMO数据应蕴含能激发模型"能力"的结构和模式